import streamlit as st
import pandas as pd
from io import BytesIO
from itertools import combinations
from dateutil.parser import parse as parse_date
import re
from collections import Counter
from itertools import combinations
import numpy as np

# Funci√≥n para buscar la fila de encabezados
def buscar_fila_encabezados(df, columnas_esperadas, max_filas=30, banco_seleccionado="Generico"):
    """
    Busca la fila que contiene al menos 'fecha' y una columna de monto (monto, debitos o creditos).
    Otras columnas son opcionales.
    """
    columnas_esperadas_lower = {col: [variante.lower().strip() for variante in variantes] 
                               for col, variantes in columnas_esperadas.items()}

    # Los campos esperados son: "fecha", "valor", "descripci√≥n"
    campos_bancolombia = [
        "fecha", 
        "valor", 
        "descripci√≥n"
    ]
    
    # Condici√≥n de Bancolombia: Coincidencia exacta de los 3 campos.

    es_bancolombia_extracto = (banco_seleccionado == "Bancolombia")

    if es_bancolombia_extracto:
        for idx in range(min(max_filas, len(df))):
            fila = df.iloc[idx]
            # Convertir celdas a min√∫sculas, SIN espacios (strip) para COINCIDENCIA EXACTA
            celdas_fila = {str(valor).lower().strip() for valor in fila if pd.notna(valor)}
            
            # Verificar si TODOS los campos obligatorios est√°n EXACTAMENTE en las celdas de la fila
            if all(campo in celdas_fila for campo in campos_bancolombia):
                # Se encontraron los encabezados exactos para Bancolombia
                return idx
        
        # Si no se encuentra con la coincidencia exacta de Bancolombia, contin√∫a con la l√≥gica general
        # o devuelve None si quieres ser estricto. Por seguridad, devolvemos None si no se encuentra 
        # para forzar al usuario a revisar el archivo.
        return None 

    for idx in range(min(max_filas, len(df))):
        fila = df.iloc[idx]
        celdas = [str(valor).lower() for valor in fila if pd.notna(valor)]

        # Variables para verificar coincidencias m√≠nimas
        tiene_fecha = False
        tiene_monto = False

       # Revisar cada celda en la fila
        for celda in celdas:
            # Verificar 'fecha'
            if 'fecha' in columnas_esperadas_lower and any(variante in celda for variante in columnas_esperadas_lower['fecha']):
                tiene_fecha = True
            # Verificar columnas de monto (monto, debitos o creditos)
            if 'monto' in columnas_esperadas_lower and any(variante in celda for variante in columnas_esperadas_lower['monto']):
                tiene_monto = True
            elif 'debitos' in columnas_esperadas_lower and any(variante in celda for variante in columnas_esperadas_lower['debitos']):
                tiene_monto = True
            elif 'creditos' in columnas_esperadas_lower and any(variante in celda for variante in columnas_esperadas_lower['creditos']):
                tiene_monto = True

        # Si se encuentran los m√≠nimos necesarios (fecha y alg√∫n monto)
        if tiene_fecha and tiene_monto:
            return idx

    return None
    
# Funci√≥n para leer datos a partir de la fila de encabezados
def leer_datos_desde_encabezados(archivo, columnas_esperadas, nombre_archivo, max_filas=30, banco_seleccionado="Generico"):
    # Determinar la extensi√≥n del archivo
    extension = archivo.name.split('.')[-1].lower()
    
    # Si es .xls, convertir a .xlsx
    if extension == 'xls':
        try:
            # Leer el archivo .xls con xlrd
            df_temp = pd.read_excel(archivo, header=None, engine='xlrd')
            # Guardar como .xlsx en un buffer
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df_temp.to_excel(writer, index=False, header=None)
            output.seek(0)
            # Actualizar el archivo a usar
            archivo = output
            st.success(f"Conversi√≥n de {nombre_archivo} de .xls a .xlsx completada.")
        except Exception as e:
            st.error(f"Error al convertir {nombre_archivo} de .xls a .xlsx: {e}")
            st.stop()
    elif extension != 'xlsx':
        st.error(f"Formato de archivo no soportado: {extension}. Usa .xls o .xlsx.")
        st.stop()
        
    # Leer el archivo de Excel sin asumir encabezados, leyendo todas las filas por defecto
    df = pd.read_excel(archivo, header=None, engine='openpyxl')
    total_filas_inicial = len(df)
    
    # Buscar la fila de encabezados
    fila_encabezados = buscar_fila_encabezados(df, columnas_esperadas, max_filas, banco_seleccionado)
    if fila_encabezados is None:
        st.error(f"No se encontraron los encabezados necesarios en el archivo {nombre_archivo}.")
        st.error(f"Se buscaron en las primeras {max_filas} filas. Se requieren al menos 'fecha' y una columna de monto (monto, debitos o creditos).")
        st.stop()

    # Leer los datos a partir de la fila de encabezados, sin limitar filas
    df = pd.read_excel(archivo, header=fila_encabezados)
    total_filas_datos = len(df)

    # Buscar la columna 'Doc Num' entre las variantes posibles antes de normalizar
    variantes_doc_num = columnas_esperadas.get('Doc Num', ["Doc Num"])  # Obtener variantes de columnas_esperadas
    doc_num_col = None
    for col in df.columns:
        col_lower = str(col).lower().strip()
        if any(variante.lower().strip() in col_lower for variante in variantes_doc_num):
            doc_num_col = col
            break
    
    # Filtrar filas donde 'Doc Num' no est√© vac√≠o
    if doc_num_col:
        filas_antes = len(df)
        # Eliminar filas donde 'Doc Num' sea NaN, None o cadena vac√≠a
        df = df[df[doc_num_col].notna() & (df[doc_num_col] != '')]
        filas_despues = len(df)
    
    # Normalizar las columnas
    df = normalizar_dataframe(df, columnas_esperadas, banco_seleccionado)
    
    # Verificar si el DataFrame tiene al menos las columnas m√≠nimas necesarias
    if 'fecha' not in df.columns:
        st.error(f"La columna obligatoria 'fecha' no se encontr√≥ en los datos le√≠dos del archivo '{nombre_archivo}'.")
        st.stop()
    
    # Verificar si existe al menos una columna de monto
    if 'monto' not in df.columns and ('debitos' not in df.columns or 'creditos' not in df.columns):
        st.error(f"No se encontr√≥ ninguna columna de monto (monto, debitos o creditos) en el archivo '{nombre_archivo}'.")
        st.stop()
    
    # Mostrar columnas detectadas (para depuraci√≥n)
    columnas_encontradas = [col for col in columnas_esperadas.keys() if col in df.columns]
    
    return df

def normalizar_dataframe(df, columnas_esperadas, banco_seleccionado="Generico"):
    """
    Normaliza un DataFrame para que use los nombres de columnas esperados y 
    elimina filas con 'fecha' o 'monto' vac√≠os.
    """
    # Convertir los nombres de las columnas del DataFrame a min√∫sculas
    df.columns = [str(col).lower().strip() for col in df.columns]
    
    # Crear un mapeo de nombres de columnas basado en las variantes
    mapeo_columnas = {}
    for col_esperada, variantes in columnas_esperadas.items():
        for variante in variantes:
            variante_lower = variante.lower().strip()
            mapeo_columnas[variante_lower] = col_esperada
    
    # Renombrar las columnas seg√∫n el mapeo
    nuevo_nombres = []
    columnas_vistas = set()
    
    for col in df.columns:
        # Verificar coincidencias aproximadas
        col_encontrada = False
        for variante, nombre_esperado in mapeo_columnas.items():
            if variante in col:
                if nombre_esperado not in columnas_vistas:
                    nuevo_nombres.append(nombre_esperado)
                    columnas_vistas.add(nombre_esperado)
                    col_encontrada = True
                    break
        
        if not col_encontrada:
            nuevo_nombres.append(col)
    
    # Asignar los nuevos nombres de columnas
    df.columns = nuevo_nombres
    
    # Eliminar columnas duplicadas despu√©s de renombrar
    df = df.loc[:, ~df.columns.duplicated(keep='first')]

    # ------------------------------------------------------------------
    ## L√≥gica para Eliminar Registros Vac√≠os en 'fecha' o 'monto'
    # Las columnas clave que siempre deben existir y no estar vac√≠as son 'fecha' y 'monto'.
    
    columnas_a_verificar = []
    if 'fecha' in df.columns:
        columnas_a_verificar.append('fecha')
    if 'monto' in df.columns:
        columnas_a_verificar.append('monto')
    
    if columnas_a_verificar:
        # Usamos dropna para eliminar filas donde CUALQUIERA de las columnas 
        # en 'subset' tenga un valor nulo (NaN, None, etc.).
        df.dropna(subset=columnas_a_verificar, inplace=True) 
        
        # Opcional: Para ser m√°s riguroso, podr√≠as querer convertir el monto a num√©rico 
        # y eliminar valores no num√©ricos, pero dropna ya maneja NaN.
        # df = df[pd.to_numeric(df['monto'], errors='coerce').notna()]
    # ------------------------------------------------------------------
    
    # Si no se encontr√≥ 'numero_movimiento', crearlo vac√≠o/generarlo
    if 'numero_movimiento' not in df.columns:
        if banco_seleccionado == "Bancolombia":
            # Caso Bancolombia: Queda vac√≠o (tal como lo solicitaste)
            df['numero_movimiento'] = ''
        else:
            # Caso Dem√°s Bancos: Genera el ID √∫nico 'DOC_' + √≠ndice.
            df['numero_movimiento'] = 'DOC_' + df.index.astype(str)  

    # L√≥gica Espec√≠fica por Banco
    if banco_seleccionado == "Davivienda":
        # Concatenar concepto (asume que "Transacci√≥n" fue mapeado a 'transaccion_davivienda' o similar)
        
        # Primero, buscamos la columna original 'Transacci√≥n'
        col_transaccion = next((col for col in df.columns if 'transacci√≥n' in col.lower()), None)
        
        # Asumimos que 'Descripci√≥n motivo' se mape√≥ a 'concepto'
        if col_transaccion and 'concepto' in df.columns:
            # Concatenar la Transacci√≥n a la Descripci√≥n motivo (columna 'concepto')
            # Es vital asegurar que el DataFrame no est√© vac√≠o despu√©s del dropna
            if not df.empty:
                 df['concepto'] = df['concepto'].astype(str) + " (" + df[col_transaccion].astype(str) + ")"
            # st.info("Davivienda: Se concaten√≥ la columna Transacci√≥n al Concepto.")
        
        # Eliminar la columna 'Valor Cheque' si existe y es in√∫til (solo en Davivienda)
        col_valor_cheque = next((col for col in df.columns if 'valor cheque' in col.lower()), None)
        if col_valor_cheque:
            df = df.drop(columns=[col_valor_cheque], errors='ignore')

    if 'numero_movimiento' not in df.columns:
        # Crea un identificador √∫nico. Si 'Documento' exist√≠a, se debe haber renombrado antes.
        df['numero_movimiento'] = 'DOC_' + df.index.astype(str)      
    
    return df
    
def detectar_formato_fechas(fechas_str, porcentaje_analisis=0.6):
    """
    Analiza un porcentaje de fechas para detectar el formato predominante (DD/MM/AAAA o MM/DD/AAAA).
    Devuelve el formato detectado y si el a√±o est√° presente.
    """
    # Filtrar fechas v√°lidas (no vac√≠as, no NaN)
    fechas_validas = [f for f in fechas_str if pd.notna(f) and f.strip() and f not in ['nan', 'NaT']]
    if not fechas_validas:
        return "desconocido", False

    # Tomar al menos el 60% de las fechas v√°lidas
    n_analizar = max(1, int(len(fechas_validas) * porcentaje_analisis))
    fechas_muestra = fechas_validas[:n_analizar]

    # Contadores para patrones
    formatos = Counter()
    tiene_a√±o = Counter()

    # Expresi√≥n regular para capturar componentes num√©ricos de la fecha
    patron_fecha = r'^(\d{1,2})[/-](\d{1,2})(?:[/-](\d{2,4}))?$'

    for fecha in fechas_muestra:
        match = re.match(patron_fecha, fecha.replace('.', '/'))
        if not match:
            continue

        comp1, comp2, comp3 = match.groups()
        comp1, comp2 = int(comp1), int(comp2)
        a√±o_presente = comp3 is not None
        tiene_a√±o[a√±o_presente] += 1

        # Determinar si el primer componente es mes (1-12) o d√≠a (1-31)
        if comp1 <= 12 and comp2 <= 31:
            # Puede ser MM/DD o DD/MM, pero si comp1 <= 12, asumimos MM/DD a menos que comp2 <= 12
            if comp2 <= 12:
                # Ambos pueden ser mes, necesitamos m√°s contexto
                formatos["ambiguo"] += 1
            else:
                formatos["MM/DD/AAAA"] += 1
        elif comp1 <= 31 and comp2 <= 12:
            formatos["DD/MM/AAAA"] += 1
        else:
            formatos["desconocido"] += 1

    # Determinar formato predominante
    formato_predominante = formatos.most_common(1)[0][0] if formatos else "desconocido"
    if formato_predominante == "ambiguo":
        # Resolver ambig√ºedad asumiendo DD/MM/AAAA (com√∫n en muchos pa√≠ses)
        formato_predominante = "DD/MM/AAAA"

    # Determinar si la mayor√≠a tiene a√±o
    a√±o_presente = tiene_a√±o.most_common(1)[0][0] if tiene_a√±o else False

    return formato_predominante, a√±o_presente

def estandarizar_fechas(df, nombre_archivo, mes_conciliacion=None, completar_anio=False, auxiliar_df=None):
    """
    Convierte la columna 'fecha' a datetime64, detectando autom√°ticamente el formato de fecha.
    Opcionalmente completa a√±os faltantes y filtra por mes de conciliaci√≥n.
    """
    if 'fecha' not in df.columns:
        st.warning(f"No se encontr√≥ la columna 'fecha' en {nombre_archivo}.")
        return df

    try:
        # Guardar copia de las fechas originales
        df['fecha_original'] = df['fecha'].copy()
        df['fecha_str'] = df['fecha'].astype(str).str.strip()

        # Determinar el a√±o base para completar fechas sin a√±o
        a√±o_base = None
        if completar_anio and auxiliar_df is not None and 'fecha' in auxiliar_df.columns:
            a√±os_validos = auxiliar_df['fecha'].dropna().apply(lambda x: x.year if pd.notna(x) else None)
            a√±o_base = a√±os_validos.mode()[0] if not a√±os_validos.empty else pd.Timestamp.now().year
        else:
            a√±o_base = pd.Timestamp.now().year

        # Detectar formato predominante solo para extracto
        es_extracto = "Extracto" in nombre_archivo
        formato_fecha = "desconocido"
        a√±o_presente = False
        if es_extracto:
            formato_fecha, a√±o_presente = detectar_formato_fechas(df['fecha_str'])
            st.write(f"Formato de fecha detectado en {nombre_archivo}: {formato_fecha}, A√±o presente: {a√±o_presente}")

        # Funci√≥n para parsear fechas
        def parsear_fecha(fecha_str, mes_conciliacion=None, a√±o_base=None, es_extracto=False, formato_fecha="desconocido"):
            if pd.isna(fecha_str) or fecha_str in ['', 'nan', 'NaT']:
                return pd.NaT

            try:
                # Normalizar separadores
                fecha_str = fecha_str.replace('-', '/').replace('.', '/')

                # Para extracto, usar formato detectado
                if es_extracto and formato_fecha != "desconocido":
                    partes = fecha_str.split('/')
                    if len(partes) >= 2:
                        comp1, comp2 = map(int, partes[:2])
                        a√±o = a√±o_base
                        if len(partes) == 3:
                            a√±o = int(partes[2])
                            if len(partes[2]) == 2:
                                a√±o += 2000 if a√±o < 50 else 1900

                        if formato_fecha == "DD/MM/AAAA":
                            dia, mes = comp1, comp2
                        else:  # MM/DD/AAAA
                            dia, mes = comp2, comp1

                        # Forzar mes_conciliacion si est√° definido
                        if mes_conciliacion and 1 <= mes <= 12:
                            mes = mes_conciliacion

                        if 1 <= dia <= 31 and 1 <= mes <= 12:
                            return pd.Timestamp(year=a√±o, month=mes, day=dia)

                # Para auxiliar o si no se detect√≥ formato, usar dateutil.parser
                parsed = parse_date(fecha_str, dayfirst=True, fuzzy=True)

                # Para extracto, ajustar mes si mes_conciliacion est√° definido
                if es_extracto and mes_conciliacion and parsed.month != mes_conciliacion:
                    return pd.Timestamp(year=parsed.year, month=mes_conciliacion, day=parsed.day)

                return parsed
            except (ValueError, TypeError):
                # Manejar fechas sin a√±o
                try:
                    partes = fecha_str.split('/')
                    if len(partes) == 2:
                        comp1, comp2 = map(int, partes[:2])
                        if formato_fecha == "DD/MM/AAAA":
                            dia, mes = comp1, comp2
                        else:  # MM/DD/AAAA o desconocido
                            dia, mes = comp2, comp1 if comp2 <= 31 and comp1 <= 12 else comp1, comp2

                        # Forzar mes_conciliacion para extracto
                        if es_extracto and mes_conciliacion:
                            mes = mes_conciliacion

                        if 1 <= dia <= 31 and 1 <= mes <= 12:
                            return pd.Timestamp(year=a√±o_base, month=mes, day=dia)
                    return pd.NaT
                except (ValueError, IndexError):
                    return pd.NaT

        # Aplicar el parseo de fechas
        df['fecha'] = df['fecha_str'].apply(
            lambda x: parsear_fecha(x, mes_conciliacion, a√±o_base, es_extracto, formato_fecha)
        )

        # Reportar fechas inv√°lidas
        fechas_invalidas = df['fecha'].isna().sum()
        if fechas_invalidas > 0:
            st.warning(f"Se encontraron {fechas_invalidas} fechas inv√°lidas en {nombre_archivo}.")
            st.write("Ejemplos de fechas inv√°lidas:")
            st.write(df[df['fecha'].isna()][['fecha_original', 'fecha_str']].head())

        # Depuraci√≥n: Mostrar fechas parseadas
        st.write(f"Fechas parseadas en {nombre_archivo} (primeras 4):")
        st.write(df[['fecha_original', 'fecha_str', 'fecha']].head(4))

        # Filtrar por mes solo para extracto si se especifica
        if mes_conciliacion and es_extracto:
            filas_antes = len(df)
            df = df[df['fecha'].dt.month == mes_conciliacion]
            if len(df) < filas_antes:
                meses = ['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio',
                         'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre']
                st.info(f"Se filtraron {filas_antes - len(df)} registros fuera del mes {meses[mes_conciliacion-1]} en {nombre_archivo}.")
                if filas_antes - len(df) > 0:
                    st.write(f"Ejemplos de fechas filtradas (no en {meses[mes_conciliacion-1]}):")
                    st.write(df[df['fecha'].dt.month != mes_conciliacion][['fecha_original', 'fecha_str', 'fecha']].head())

        # Limpiar columnas temporales
        df = df.drop(['fecha_str'], axis=1, errors='ignore')

    except Exception as e:
        st.error(f"Error al estandarizar fechas en {nombre_archivo}: {e}")
        return df

    return df
    
def procesar_montos(df, nombre_archivo, es_extracto=False, invertir_signos=False, banco_seleccionado="Generico"):
    """
    Procesa columnas de d√©bitos y cr√©ditos para crear una columna 'monto' unificada,
    aplicando l√≥gica espec√≠fica seg√∫n el banco seleccionado.
    """
    import pandas as pd
    import streamlit as st # Aseg√∫rate de que st est√© accesible

    # --- Funci√≥n auxiliar de limpieza LATINO (Manejo Bancolombia y Gen√©rico) ---
    # Esta es la versi√≥n robusta que funciona para Bancolombia (punto decimal)
    def limpiar_monto_bancolombia_generico(series):
        series_str = series.astype(str).str.strip()
        
        # 1. Asegurar que el signo negativo se mantenga
        series_str = series_str.str.replace(r'([,\.])(\-)', r'\2\1', regex=True)
        
        # 2. Eliminar cualquier caracter que no sea d√≠gito, punto, coma o signo negativo.
        series_str = series_str.str.replace(r'[^\d\.\,\-]', '', regex=True)

        # 3. Quitar separador de miles (coma) para que Pandas solo vea el punto decimal.
        # Esto asume que el formato es est√°ndar (punto decimal, coma miles).
        series_str = series_str.str.replace(',', '', regex=False) 
        
        return pd.to_numeric(series_str, errors='coerce')
    # -------------------------------------------------------------------------
    
    # --- Funci√≥n auxiliar de limpieza DAVIVIENDA (Manejo de coma como decimal) ---
    def limpiar_monto_davivienda(series):
        series_str = series.astype(str).str.strip()
        # 1. Limpia todo excepto d√≠gitos, punto y coma.
        series_str = series_str.str.replace(r'[^\d\.\,]+', '', regex=True)
        # 2. Quita el punto (separador de miles).
        series_str = series_str.str.replace('.', '', regex=False)
        # 3. Cambia la coma por punto (separador decimal).
        series_str = series_str.str.replace(',', '.', regex=False) 
        return pd.to_numeric(series_str, errors='coerce')
    # -------------------------------------------------------------------------

    columnas = df.columns.str.lower()

    # --- L√≥gica de Manejo de Monto √önico ---
    if "monto" in columnas and df["monto"].notna().any() and (df["monto"] != 0).any():
        
        # 1. Limpieza y Conversi√≥n Espec√≠fica por Banco
        if es_extracto and banco_seleccionado == "Davivienda":
            # üéØ L√ìGICA DAVIVIENDA (Monto √∫nico, usa la limpieza espec√≠fica de coma decimal)
            df["monto"] = limpiar_monto_davivienda(df["monto"]).fillna(0)
            
            # --- L√ìGICA ESPEC√çFICA DE SIGNO Y CONCEPTO PARA DAVIVIENDA ---
            if df["monto"].abs().sum() > 0 and 'concepto' in df.columns:
                
                terminos_debito = ['d√©bito', 'debito', 'nota d√©bito', 'cargo', 'retiro', 'dcto', 'descuento']
                es_debito_extracto = df['concepto'].astype(str).str.lower().apply(lambda x: any(term in x for term in terminos_debito))

                if not invertir_signos:
                    df.loc[es_debito_extracto & (df['monto'] > 0), 'monto'] *= -1
                else:
                    df.loc[es_debito_extracto & (df['monto'] < 0), 'monto'] *= -1

                st.success("Davivienda: L√≥gica de signos y formato 'coma decimal' aplicada correctamente.")
            # ------------------------------------------------------------
            
        elif es_extracto and banco_seleccionado == "Bancolombia":
            # üéØ L√ìGICA BANCOLOMBIA (Monto √∫nico, usa la limpieza de punto decimal)
            st.info("Bancolombia detectado: Aplicando limpieza de formato num√©rico (punto decimal) al monto √∫nico.")
            
            df["monto"] = limpiar_monto_bancolombia_generico(df["monto"]).fillna(0)
            
            # Si se seleccion√≥ invertir_signos, lo aplicamos directamente al monto:
            if invertir_signos:
                df['monto'] *= -1
                st.info("Se invirtieron los signos de la columna 'monto' de Bancolombia.")
        # ------------------------------------

        else:
            # BBVA/Bogot√°/Auxiliar/Gen√©rico con monto √∫nico: Conversi√≥n con l√≥gica de Bancolombia
            # Asumimos que la l√≥gica Bancolombia/Generico (punto decimal) es la m√°s com√∫n si no hay reglas.
            df["monto"] = limpiar_monto_bancolombia_generico(df["monto"]).fillna(0)

        # Advertencia final
        if df["monto"].abs().sum() == 0 and df.shape[0] > 0:
            st.warning(f"La columna 'monto' de {nombre_archivo} result√≥ en ceros. Revise la columna de Monto y el tipo de movimiento.")
            
        return df

    # [BLOQUE 2: MANEJO DE D√âBITOS Y CR√âDITOS SEPARADOS]
    
    # ... (El c√≥digo de tu l√≥gica original para encontrar y definir signos de d√©bitos/cr√©ditos separados) ...
    
    # Definir t√©rminos para identificar d√©bitos y cr√©ditos
    terminos_debitos = ["deb", "debe", "cargo", "d√©bito", "valor d√©bito"]
    terminos_creditos = ["cred", "haber", "abono", "cr√©dito", "valor cr√©dito"]
    cols_debito = [col for col in df.columns if any(term in col.lower() for term in terminos_debitos)]
    cols_credito = [col for col in df.columns if any(term in col.lower() for term in terminos_creditos)]

    # Si no hay columnas de monto, d√©bitos ni cr√©ditos, advertir
    if not cols_debito and not cols_credito and "monto" not in columnas:
        st.warning(f"No se encontraron columnas de monto, d√©bitos o cr√©ditos en {nombre_archivo}.")
        return df

    # Inicializar columna 'monto'
    df["monto"] = 0.0

    # Definir signos seg√∫n el tipo de archivo y si se invierten
    if es_extracto:
        signo_debito = 1 if invertir_signos else -1
        signo_credito = -1 if invertir_signos else 1
    else:
        signo_debito = 1
        signo_credito = -1

    # Ciclo de procesamiento de D√âBITOS
    for col in cols_debito:
        try:
            # 1. INTENTO SIMPLE
            simple_conversion = pd.to_numeric(df[col], errors='coerce')
            valid_count = simple_conversion.notna().sum()
            
            # 2. L√ìGICA CONDICIONAL DE LIMPIEZA
            # Aplicar limpieza ESPEC√çFICA de Davivienda si se detecta, de lo contrario, la de Bancolombia/Gen√©rico.
            if es_extracto and banco_seleccionado == "Davivienda":
                 st.info(f"Aplicando limpieza Davivienda a columna de d√©bito '{col}'.")
                 cleaned_series = limpiar_monto_davivienda(df[col]).fillna(0)
                 
            elif es_extracto and banco_seleccionado == "Bancolombia":
                 # Bancolombia no tiene d√©bitos/cr√©ditos separados en su formato t√≠pico, 
                 # pero si los tuviera, usar√≠a la l√≥gica Bancolombia/Gen√©rico.
                 st.info(f"Aplicando limpieza Bancolombia/Gen√©rico a columna de d√©bito '{col}'.")
                 cleaned_series = limpiar_monto_bancolombia_generico(df[col]).fillna(0)

            # L√≥gica de detecci√≥n autom√°tica para 'Generico' o no especificado.
            elif es_extracto and valid_count < (len(df) * 0.05):
                 st.info(f"Aplicando limpieza Bancolombia/Gen√©rico (detecci√≥n autom√°tica) a la columna de d√©bito '{col}' en {nombre_archivo}.")
                 cleaned_series = limpiar_monto_bancolombia_generico(df[col]).fillna(0)
            
            else:
                 # Caso Auxiliar, BBVA/Bogot√° o si la conversi√≥n simple funcion√≥
                 cleaned_series = simple_conversion.fillna(0)
            
            df[col] = cleaned_series
            df["monto"] += cleaned_series * signo_debito
            
        except Exception as e:
            st.warning(f"Error al procesar columna de d√©bito '{col}' en {nombre_archivo}: {e}")

    # Ciclo de procesamiento de CR√âDITOS
    for col in cols_credito:
        try:
            # 1. INTENTO SIMPLE
            simple_conversion = pd.to_numeric(df[col], errors='coerce')
            valid_count = simple_conversion.notna().sum()
            
            # 2. L√ìGICA CONDICIONAL DE LIMPIEZA
            if es_extracto and banco_seleccionado == "Davivienda":
                 st.info(f"Aplicando limpieza Davivienda a columna de cr√©dito '{col}'.")
                 cleaned_series = limpiar_monto_davivienda(df[col]).fillna(0)
                 
            elif es_extracto and banco_seleccionado == "Bancolombia":
                 # Bancolombia usar√≠a l√≥gica Bancolombia/Gen√©rico si tuviera columnas separadas.
                 st.info(f"Aplicando limpieza Bancolombia/Gen√©rico a columna de cr√©dito '{col}'.")
                 cleaned_series = limpiar_monto_bancolombia_generico(df[col]).fillna(0)

            # L√≥gica de detecci√≥n autom√°tica para 'Generico' o no especificado.
            elif es_extracto and valid_count < (len(df) * 0.05):
                 st.info(f"Aplicando limpieza Bancolombia/Gen√©rico (detecci√≥n autom√°tica) a la columna de cr√©dito '{col}' en {nombre_archivo}.")
                 cleaned_series = limpiar_monto_bancolombia_generico(df[col]).fillna(0)
            
            else:
                 cleaned_series = simple_conversion.fillna(0)
            
            df[col] = cleaned_series
            df["monto"] += cleaned_series * signo_credito

        except Exception as e:
            st.warning(f"Error al procesar columna de cr√©dito '{col}' en {nombre_archivo}: {e}")
    
    # [C√ìDIGO ORIGINAL - L√≥gica de verificaci√≥n final]
    if df["monto"].eq(0).all() and (cols_debito or cols_credito):
        st.warning(f"La columna 'monto' result√≥ en ceros en {nombre_archivo}. Verifica las columnas de d√©bitos/cr√©ditos.")

    # [C√ìDIGO ORIGINAL - L√≥gica de verificaci√≥n final]
    # (Lo mantenemos para advertir si todo el DF resulta en cero)
    if df["monto"].eq(0).all() and (cols_debito or cols_credito) and not es_extracto:
        st.warning(f"La columna 'monto' result√≥ en ceros en {nombre_archivo}. Verifica las columnas de d√©bitos/cr√©ditos.")

    # üåü FILTRO FINAL: ELIMINAR MONTOS CERO Y NaN EN EL EXTRACTO BANCARIO üåü
    if es_extracto and 'monto' in df.columns and not df.empty:
        filas_antes = len(df)
        
        # --- NUEVA L√ìGICA: Combina la eliminaci√≥n de ceros con la correcci√≥n de errores de punto flotante ---
        
        # 1. Aplicar redondeo para tratar como 0 cualquier residuo de punto flotante (ej: 1e-15)
        df['monto_redondeado'] = df['monto'].round(2)
        
        # 2. **Filtrado:** Eliminar filas donde el monto redondeado es EXACTAMENTE cero.
        # Esto incluye los montos reales de 0 y los NaN que se convirtieron a 0 por .fillna(0)
        df_filtrado = df[df['monto_redondeado'] != 0.00].copy()
        
        # 3. Limpieza final: Eliminar la columna auxiliar
        df_filtrado = df_filtrado.drop(columns=['monto_redondeado'])
        df = df_filtrado
        
        # --- Mensaje de √©xito ---
        filas_despues = len(df)
        if filas_antes > filas_despues:
            st.info(f"Se eliminaron {filas_antes - filas_despues} registros con monto cero (incluyendo vac√≠os/no num√©ricos) del Extracto Bancario. ‚úÖ")
            
    return df
    
# Funci√≥n para encontrar combinaciones que sumen un monto espec√≠fico
def encontrar_combinaciones(df, monto_objetivo, tolerancia=0.01, max_combinacion=4):
    """
    Encuentra combinaciones de valores en df['monto'] que sumen aproximadamente monto_objetivo.
    Restringe la b√∫squeda a valores del MISMO SIGNO que el objetivo.
    Devuelve lista de √≠ndices de las filas que conforman la combinaci√≥n.
    """
    
    # 1. Preparar monto_objetivo y determinar el signo
    try:
        monto_objetivo = float(monto_objetivo)
    except (ValueError, TypeError):
        return []

    # Determinar si el objetivo es positivo o negativo.
    # Usamos la tolerancia para incluir los ceros en el grupo adecuado.
    es_objetivo_positivo = monto_objetivo >= 0 
    
    movimientos = []
    indices_validos = []
    
    # 2. Iterar y filtrar por signo
    for idx, valor in zip(df.index, df["monto"]):
        try:
            valor_num = float(valor)
            
            # --- L√ìGICA DE FILTRADO DE SIGNO (NUEVA) ---
            # Si el objetivo es positivo, solo incluimos valores >= -tolerancia (casi cero o positivo)
            if es_objetivo_positivo and valor_num < -tolerancia:
                continue
            
            # Si el objetivo es negativo, solo incluimos valores <= tolerancia (casi cero o negativo)
            if not es_objetivo_positivo and valor_num > tolerancia:
                continue
            # -------------------------------------------

            movimientos.append(valor_num)
            indices_validos.append(idx)
        except (ValueError, TypeError):
            # Ignorar valores que no se pueden convertir a flotante
            continue
    
    if not movimientos:
        return []
        
    combinaciones_validas = []
    
    # 3. Buscar combinaciones (la l√≥gica sigue igual)
    
    # Limitar la b√∫squeda a combinaciones peque√±as
    for r in range(1, min(max_combinacion, len(movimientos)) + 1):
        for combo_indices in combinations(range(len(movimientos)), r):
            combo_valores = [movimientos[i] for i in combo_indices]
            suma = sum(combo_valores)
            
            # NOTA: La tolerancia en el filtro inicial ya maneja los ceros.
            if abs(suma - monto_objetivo) <= tolerancia:
                indices_combinacion = [indices_validos[i] for i in combo_indices]
                combinaciones_validas.append((indices_combinacion, combo_valores))
    
    # Ordenar por tama√±o de combinaci√≥n (preferimos las m√°s peque√±as)
    combinaciones_validas.sort(key=lambda x: len(x[0]))
    
    if combinaciones_validas:
        return combinaciones_validas[0][0]  # Devolver los √≠ndices de la mejor combinaci√≥n
    return []

# Funci√≥n para la conciliaci√≥n directa (uno a uno)
def conciliacion_directa(extracto_df, auxiliar_df):
    """
    Realiza la conciliaci√≥n directa entre el extracto bancario y el libro auxiliar.
    Empareja registros por fecha y monto, asegurando una relaci√≥n 1:1 sin reutilizar registros.
    El numero_movimiento puede repetirse y no se usa como criterio de unicidad.
    """
    resultados = []
    extracto_conciliado_idx = set()
    auxiliar_conciliado_idx = set()
    
    # Crear copias para no modificar los DataFrames originales
    extracto_df = extracto_df.copy()
    auxiliar_df = auxiliar_df.copy()
    extracto_df['fecha_solo'] = extracto_df['fecha'].dt.date
    auxiliar_df['fecha_solo'] = auxiliar_df['fecha'].dt.date
        
    # Iterar sobre el extracto
    for idx_extracto, fila_extracto in extracto_df.iterrows():
        if idx_extracto in extracto_conciliado_idx or pd.isna(fila_extracto['fecha_solo']):
            continue
        
        # Filtrar registros del auxiliar no conciliados
        auxiliar_no_conciliado = auxiliar_df[~auxiliar_df.index.isin(auxiliar_conciliado_idx)]
        
        # Buscar coincidencias por fecha y monto
        coincidencias = auxiliar_no_conciliado[
            (auxiliar_no_conciliado['fecha_solo'] == fila_extracto['fecha_solo']) & 
            (abs(auxiliar_no_conciliado['monto'] - fila_extracto['monto']) < 0.01)
        ]
        
        if not coincidencias.empty:
            # Tomar el primer registro no conciliado del auxiliar
            idx_auxiliar = coincidencias.index[0]
            fila_auxiliar = coincidencias.iloc[0]
            
            # Marcar como conciliados
            extracto_conciliado_idx.add(idx_extracto)
            auxiliar_conciliado_idx.add(idx_auxiliar)
            
            # A√±adir entrada del extracto bancario
            resultados.append({
                'fecha': fila_extracto['fecha'],
                'tercero': '',
                'concepto': fila_extracto.get('concepto', ''),
                'numero_movimiento': fila_extracto.get('numero_movimiento', ''),
                'monto': fila_extracto['monto'],
                'origen': 'Banco',
                'estado': 'Conciliado',
                'tipo_conciliacion': 'Directa',
                'doc_conciliacion': fila_auxiliar.get('numero_movimiento', ''),
                'index_original': idx_extracto,
                'tipo_registro': 'extracto'
            })

            # A√±adir entrada del libro auxiliar
            resultados.append({
                'fecha': fila_auxiliar['fecha'],
                'tercero': fila_auxiliar.get('tercero', ''),
                'concepto': fila_auxiliar.get('nota', ''),
                'numero_movimiento': fila_auxiliar.get('numero_movimiento', ''),
                'monto': fila_auxiliar['monto'],
                'origen': 'Libro Auxiliar',
                'estado': 'Conciliado',
                'tipo_conciliacion': 'Directa',
                'doc_conciliacion': fila_extracto.get('numero_movimiento', ''),
                'index_original': idx_auxiliar,
                'tipo_registro': 'auxiliar'
            })
    
    # Agregar registros no conciliados del extracto
    for idx_extracto, fila_extracto in extracto_df.iterrows():
        if idx_extracto not in extracto_conciliado_idx:
            resultados.append({
                'fecha': fila_extracto["fecha"],
                'tercero': '',
                'concepto': fila_extracto.get("concepto", ""),
                'numero_movimiento': fila_extracto.get("numero_movimiento", ""),
                'monto': fila_extracto["monto"],
                'origen': 'Banco',
                'estado': 'No Conciliado',
                'tipo_conciliacion': '',
                'doc_conciliacion': '',
                'index_original': idx_extracto,
                'tipo_registro': 'extracto'
            })
    
    # Agregar registros no conciliados del libro auxiliar
    for idx_auxiliar, fila_auxiliar in auxiliar_df.iterrows():
        if idx_auxiliar not in auxiliar_conciliado_idx:
            resultados.append({
                'fecha': fila_auxiliar["fecha"],
                'tercero': fila_auxiliar.get('tercero', ''),
                'concepto': fila_auxiliar.get("nota", ""),
                'numero_movimiento': fila_auxiliar.get("numero_movimiento", ""),
                'monto': fila_auxiliar["monto"],
                'origen': 'Libro Auxiliar',
                'estado': 'No Conciliado',
                'tipo_conciliacion': '',
                'doc_conciliacion': '',
                'index_original': idx_auxiliar,
                'tipo_registro': 'auxiliar'
            })
    
    resultados_df = pd.DataFrame(resultados)
    return resultados_df, extracto_conciliado_idx, auxiliar_conciliado_idx

def conciliacion_agrupacion_auxiliar(extracto_df, auxiliar_df, extracto_conciliado_idx, auxiliar_conciliado_idx):
    """
    Busca grupos de valores en el libro auxiliar que sumen el monto de un movimiento en el extracto.
    Garantiza que cada registro del auxiliar se concilie solo una vez, manteniendo objetos datetime.
    """
    import pandas as pd
    
    resultados = []
    nuevos_extracto_conciliado = set()
    nuevos_auxiliar_conciliado = set()
    
    # Filtrar los registros a√∫n no conciliados
    extracto_no_conciliado = extracto_df[~extracto_df.index.isin(extracto_conciliado_idx)].copy()
    auxiliar_no_conciliado = auxiliar_df[~auxiliar_df.index.isin(auxiliar_conciliado_idx)].copy()
    
    # Creamos una lista de √≠ndices del extracto para iterar de forma segura
    indices_extracto_a_iterar = extracto_no_conciliado.index.tolist()

    for idx_extracto in indices_extracto_a_iterar:
        if idx_extracto not in extracto_no_conciliado.index:
            continue
            
        fila_extracto = extracto_no_conciliado.loc[idx_extracto]

        # Buscar combinaciones en el libro auxiliar (con filtro de signo incluido)
        indices_combinacion = encontrar_combinaciones(
            auxiliar_no_conciliado, 
            fila_extracto["monto"],
            tolerancia=0.01
        )
        
        if indices_combinacion:
            # 1. Marcar como conciliados (para el set de retorno)
            nuevos_extracto_conciliado.add(idx_extracto)
            nuevos_auxiliar_conciliado.update(indices_combinacion)
            
            # 2. **ACTUALIZACI√ìN CR√çTICA (UNICIDAD)**: Eliminar los √≠ndices usados del DataFrame de trabajo del auxiliar.
            auxiliar_no_conciliado = auxiliar_no_conciliado.drop(indices_combinacion, errors='ignore')
            
            # 3. **FECHA**: Usamos el objeto datetime original (¬°REVERTIDO!)
            fecha_extracto = fila_extracto["fecha"] 

            # 4. Obtener n√∫meros de documento
            docs_conciliacion = auxiliar_df.loc[indices_combinacion, "numero_movimiento"].astype(str).tolist()
            docs_conciliacion = [str(doc) for doc in docs_conciliacion]
            
            # A√±adir a resultados - Movimiento del extracto
            resultados.append({
                'fecha': fecha_extracto, # <--- OBJETO DATETIME
                'tercero': '',
                'concepto': fila_extracto.get("concepto", ""),
                'numero_movimiento': fila_extracto.get("numero_movimiento", ""),
                'monto': fila_extracto["monto"],
                'origen': 'Banco',
                'estado': 'Conciliado',
                'tipo_conciliacion': 'Agrupaci√≥n en Libro Auxiliar',
                'doc_conciliacion': ", ".join(docs_conciliacion),
                'index_original': idx_extracto,
                'tipo_registro': 'extracto'
            })
            
            # A√±adir a resultados - Cada movimiento del libro auxiliar en la combinaci√≥n
            for idx_aux in indices_combinacion:
                fila_aux = auxiliar_df.loc[idx_aux] # Usamos el auxiliar_df original
                
                # FECHA: Revertimos a usar el objeto datetime original (¬°REVERTIDO!)
                fecha_auxiliar = fila_aux["fecha"] 
                
                resultados.append({
                    'fecha': fecha_auxiliar, # <--- OBJETO DATETIME
                    'tercero': fila_aux.get("tercero", ""),
                    'concepto': fila_aux.get("nota", ""),
                    'numero_movimiento': fila_aux.get("numero_movimiento", ""),
                    'monto': fila_aux["monto"],
                    'origen': 'Libro Auxiliar',
                    'estado': 'Conciliado',
                    'tipo_conciliacion': 'Agrupaci√≥n en Libro Auxiliar',
                    'doc_conciliacion': fila_extracto.get("numero_movimiento", ""),
                    'index_original': idx_aux,
                    'tipo_registro': 'auxiliar'
                })
    
    return pd.DataFrame(resultados), nuevos_extracto_conciliado, nuevos_auxiliar_conciliado
    
def conciliacion_agrupacion_extracto(extracto_df, auxiliar_df, extracto_conciliado_idx, auxiliar_conciliado_idx):
    """
    Busca grupos de valores en el extracto que sumen el monto de un movimiento en el libro auxiliar.
    Garantiza que cada registro del extracto se concilie solo una vez y aplica formato de fecha DD/MM/YYYY.
    """
    import pandas as pd
    
    resultados = []
    nuevos_extracto_conciliado = set()
    nuevos_auxiliar_conciliado = set()
    
    # Filtrar los registros a√∫n no conciliados (usamos .copy() para evitar SettingWithCopyWarning)
    extracto_no_conciliado = extracto_df[~extracto_df.index.isin(extracto_conciliado_idx)].copy()
    auxiliar_no_conciliado = auxiliar_df[~auxiliar_df.index.isin(auxiliar_conciliado_idx)].copy()
    
    # Creamos una lista de √≠ndices del auxiliar para iterar de forma segura
    indices_auxiliar_a_iterar = auxiliar_no_conciliado.index.tolist()
    
    # Para cada movimiento no conciliado del libro auxiliar
    for idx_auxiliar in indices_auxiliar_a_iterar:
        # Si la fila ha sido movida por alg√∫n otro proceso (poco probable aqu√≠), saltar
        if idx_auxiliar not in auxiliar_no_conciliado.index:
            continue
            
        fila_auxiliar = auxiliar_no_conciliado.loc[idx_auxiliar]

        # Buscar combinaciones en el extracto (con filtro de signo incluido)
        indices_combinacion = encontrar_combinaciones(
            extracto_no_conciliado, 
            fila_auxiliar["monto"],
            tolerancia=0.01
        )
        
        if indices_combinacion:
            # 1. Marcar como conciliados (para el set de retorno)
            nuevos_auxiliar_conciliado.add(idx_auxiliar)
            nuevos_extracto_conciliado.update(indices_combinacion)
            
            # 2. **ACTUALIZACI√ìN CR√çTICA (UNICIDAD)**: Eliminar los √≠ndices usados del DataFrame de trabajo del extracto.
            # Esto evita que los registros del extracto se reutilicen en la siguiente iteraci√≥n del auxiliar.
            extracto_no_conciliado = extracto_no_conciliado.drop(indices_combinacion, errors='ignore')
                        
            # 4. Obtener n√∫meros de movimiento (usamos el extracto_df original para evitar errores)
            nums_movimiento = extracto_df.loc[indices_combinacion, "numero_movimiento"].astype(str).tolist()
            nums_movimiento = [str(num) for num in nums_movimiento]
            
            # A√±adir a resultados - Movimiento del libro auxiliar
            resultados.append({
                'fecha': fecha_auxiliar_str,
                'tercero': fila_auxiliar.get('tercero', ''),
                'concepto': fila_auxiliar.get("nota", ""),
                'numero_movimiento': fila_auxiliar.get("numero_movimiento", ""),
                'monto': fila_auxiliar["monto"],
                'origen': 'Libro Auxiliar',
                'estado': 'Conciliado',
                'tipo_conciliacion': 'Agrupaci√≥n en Extracto Bancario',
                'doc_conciliacion': ", ".join(nums_movimiento),
                'index_original': idx_auxiliar,
                'tipo_registro': 'auxiliar'
            })
            
            # A√±adir a resultados - Cada movimiento del extracto en la combinaci√≥n
            for idx_ext in indices_combinacion:
                fila_ext = extracto_df.loc[idx_ext] # Usamos el extracto_df original
                
                # Formato de fecha para la l√≠nea del extracto
                fecha_extracto_str = fila_ext["fecha"].strftime('%d/%m/%Y')
                
                resultados.append({
                    'fecha': fecha_extracto_str,
                    'tercero': '',
                    'concepto': fila_ext.get("concepto", ""),
                    'numero_movimiento': fila_ext.get("numero_movimiento", ""),
                    'monto': fila_ext["monto"],
                    'origen': 'Banco',
                    'estado': 'Conciliado',
                    'tipo_conciliacion': 'Agrupaci√≥n en Extracto Bancario',
                    'doc_conciliacion': fila_auxiliar.get("numero_movimiento", ""),
                    'index_original': idx_ext,
                    'tipo_registro': 'extracto'
                })
    
    return pd.DataFrame(resultados), nuevos_extracto_conciliado, nuevos_auxiliar_conciliado

# Funci√≥n principal de conciliaci√≥n
def conciliar_banco_completo(extracto_df, auxiliar_df):
    """
    Implementa la l√≥gica completa de conciliaci√≥n.
    """

    # üåü CORRECCI√ìN CR√çTICA DE FECHA DEL LIBRO AUXILIAR üåü
    # Esto garantiza que 02/05/2025 se interprete correctamente como 5 de Febrero,
    # resolviendo la ambig√ºedad que rompe la conciliaci√≥n directa.
    if 'fecha' in auxiliar_df.columns:
        # Forzar el re-parseo, asumiendo que el auxiliar SIEMPRE viene DD/MM/YYYY
        auxiliar_df['fecha'] = pd.to_datetime(
            auxiliar_df['fecha'], 
            format='%d/%m/%Y', 
            errors='coerce' # Si falla, ser√° NaT, lo que tu l√≥gica ya maneja
        )
        
    # 1. Conciliaci√≥n directa (uno a uno)
    resultados_directa, extracto_conciliado_idx, auxiliar_conciliado_idx = conciliacion_directa(
        extracto_df, auxiliar_df
    )
    
    # 2. Conciliaci√≥n por agrupaci√≥n en el libro auxiliar
    resultados_agrup_aux, nuevos_extracto_conc1, nuevos_auxiliar_conc1 = conciliacion_agrupacion_auxiliar(
        extracto_df, auxiliar_df, extracto_conciliado_idx, auxiliar_conciliado_idx
    )
    
    # Actualizar √≠ndices de conciliados
    extracto_conciliado_idx.update(nuevos_extracto_conc1)
    auxiliar_conciliado_idx.update(nuevos_auxiliar_conc1)
    
    # 3. Conciliaci√≥n por agrupaci√≥n en el extracto bancario
    resultados_agrup_ext, nuevos_extracto_conc2, nuevos_auxiliar_conc2 = conciliacion_agrupacion_extracto(
        extracto_df, auxiliar_df, extracto_conciliado_idx, auxiliar_conciliado_idx
    )
    
    # Filtrar resultados directos para eliminar los que luego fueron conciliados por agrupaci√≥n
    if not resultados_directa.empty:
        # Eliminar los registros no conciliados que luego se conciliaron por agrupaci√≥n
        indices_a_eliminar = []
        for idx, fila in resultados_directa.iterrows():
            if fila['estado'] == 'No Conciliado':
                if (fila['tipo_registro'] == 'extracto' and fila['index_original'] in nuevos_extracto_conc1.union(nuevos_extracto_conc2)) or \
                   (fila['tipo_registro'] == 'auxiliar' and fila['index_original'] in nuevos_auxiliar_conc1.union(nuevos_auxiliar_conc2)):
                    indices_a_eliminar.append(idx)
        
        # Eliminar los registros identificados
        if indices_a_eliminar:
            resultados_directa = resultados_directa.drop(indices_a_eliminar)
    
    # Combinar resultados
    resultados_finales = pd.concat([
        resultados_directa,
        resultados_agrup_aux,
        resultados_agrup_ext
    ], ignore_index=True)
    
    # üåü SOLUCI√ìN DEFINITIVA: FILTRAR SOLO MONTO CERO CON ORIGEN EN EL BANCO üåü
    if 'monto' in resultados_finales.columns and 'origen' in resultados_finales.columns and not resultados_finales.empty:
        
        # 1. Identificar todos los registros con monto exactamente cero (o muy cercano)
        monto_es_cero = (resultados_finales['monto'].abs().round(2) == 0.00)
        
        # 2. Definir el filtro para MANTENER las filas:
        #    a) Las que NO tienen monto cero, O
        #    b) Las que S√ç tienen monto cero, PERO son del 'Libro Auxiliar'
        filtro_final = (~monto_es_cero) | (monto_es_cero & (resultados_finales['origen'] == 'Libro Auxiliar'))
        
        # Aplicar el filtro
        resultados_finales = resultados_finales[filtro_final].copy()
    
    # Eliminar columnas auxiliares antes de devolver los resultados finales
    if 'index_original' in resultados_finales.columns:
        resultados_finales = resultados_finales.drop(['index_original', 'tipo_registro'], axis=1)
    
    return resultados_finales

def aplicar_formato_excel(writer, resultados_df):
    """
    Aplica formatos espec√≠ficos (encabezados, fechas, moneda, no conciliados) 
    al DataFrame de resultados antes de guardarlo en Excel.
    """
    
    # ----------------------------------------------------
    # CAMBIO CR√çTICO: Asegurar que la columna 'fecha' sea datetime y que 
    # interprete el d√≠a primero (DD/MM/YYYY) para corregir inconsistencias visuales.
    # ----------------------------------------------------
    try:
        # Intenta convertir la columna 'fecha' al formato datetime de Pandas.
        # Usa errors='coerce' para convertir fechas inv√°lidas a NaT (Not a Time).
        # Se a√±ade dayfirst=True para forzar la interpretaci√≥n de fechas como DD/MM/YYYY.
        resultados_df['fecha'] = pd.to_datetime(resultados_df['fecha'], errors='coerce', dayfirst=True)
    except KeyError:
        # En caso de que la columna 'fecha' no exista, se ignora (aunque es poco probable)
        pass
    # ----------------------------------------------------

    worksheet = writer.sheets['Resultados']
    workbook = writer.book
    
    formato_encabezado = workbook.add_format({
        'bold': True, 'align': 'center', 'valign': 'vcenter', 'text_wrap': True,
        'border': 1, 'bg_color': '#D9E1F2'
    })
    # Se usa 'dd/mm/yyyy' para forzar el formato deseado en Excel
    formato_fecha = workbook.add_format({'num_format': 'dd/mm/yyyy'})
    formato_moneda = workbook.add_format({'num_format': '_($* #,##0.00_);_($* (#,##0.00);_($* "-"??_);_(@_)'})
    formato_no_conciliado = workbook.add_format({'bg_color': '#FFCCCB'})
    
    anchuras = {'fecha': 12, 'tercero': 30, 'concepto': 30, 'monto': 15}
    for i, col in enumerate(resultados_df.columns):
        ancho = anchuras.get(col.lower(), 14)
        worksheet.set_column(i, i, ancho)
    
    for i, col in enumerate(resultados_df.columns):
        worksheet.write(0, i, col, formato_encabezado)
    
    worksheet.freeze_panes(1, 0)
    
    for i, col in enumerate(resultados_df.columns):
        col_lower = col.lower()
        
        if col_lower == 'fecha':
            for row_num in range(1, len(resultados_df) + 1):
                valor = resultados_df.iloc[row_num-1][col]
                # Verifica si el valor no es NaT (la versi√≥n datetime de NaN)
                if pd.isna(valor):
                    worksheet.write(row_num, i, "", formato_fecha)
                else:
                    # Este m√©todo ahora funciona porque el valor es garantizado ser un datetime object
                    worksheet.write_datetime(row_num, i, valor, formato_fecha)
        
        elif col_lower == 'monto':
            for row_num in range(1, len(resultados_df) + 1):
                valor = resultados_df.iloc[row_num-1][col]
                if pd.isna(valor):
                    worksheet.write(row_num, i, "", formato_moneda)
                else:
                    worksheet.write_number(row_num, i, valor, formato_moneda)
        
        elif col_lower == 'estado':
            for row_num in range(1, len(resultados_df) + 1):
                estado = resultados_df.iloc[row_num-1][col]
                if estado == 'No Conciliado':
                    for col_idx in range(len(resultados_df.columns)):
                        # Escribir el estado en la celda 'estado'
                        if col_idx == i:
                            worksheet.write(row_num, col_idx, estado, formato_no_conciliado)
                        else:
                            # Aplicar formato de fila 'No Conciliado'
                            col_name = resultados_df.columns[col_idx]
                            valor = resultados_df.iloc[row_num-1][col_name]
                            
                            if col_name.lower() == 'fecha':
                                formato_combinado = workbook.add_format({'num_format': 'dd/mm/yyyy', 'bg_color': '#FFCCCB'})
                                if pd.isna(valor):
                                    worksheet.write(row_num, col_idx, "", formato_combinado)
                                else:
                                    # Usa write_datetime para fechas
                                    worksheet.write_datetime(row_num, col_idx, valor, formato_combinado)
                                    
                            elif col_name.lower() == 'monto':
                                formato_combinado = workbook.add_format({'num_format': '_($* #,##0.00_);_($* (#,##0.00);_($* "-"??_);_(@_)', 'bg_color': '#FFCCCB'})
                                if pd.isna(valor):
                                    worksheet.write(row_num, col_idx, "", formato_combinado)
                                else:
                                    # Usa write_number para montos
                                    worksheet.write_number(row_num, col_idx, valor, formato_combinado)
                            else:
                                # Usa write para otros tipos (texto/general)
                                worksheet.write(row_num, col_idx, valor, formato_no_conciliado)

# Interfaz de Streamlit
st.title("Herramienta de Conciliaci√≥n Bancaria Autom√°tica")

# 1. Selector de Banco (Nuevo)
BANCOS = ["Generico", "BBVA", "Bogot√°", "Davivienda", "Bancolombia"]
banco_seleccionado = st.selectbox(
    "Selecciona el Banco:",
    BANCOS,
    key="banco_seleccionado"
)

st.subheader("Configuraci√≥n")
meses = ["Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio", "Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre"]
mes_seleccionado = st.selectbox("Mes a conciliar (opcional):", ["Todos"] + meses)
mes_conciliacion = meses.index(mes_seleccionado) + 1 if mes_seleccionado != "Todos" else None

tipos_aceptados = [
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",  # .xlsx
    "application/vnd.ms-excel",  # .xls
    "application/excel",  # Variante .xls
    "application/x-excel",  # Variante .xls
    "application/x-msexcel",  # Variante .xls
    "application/octet-stream"  # Por si el navegador lo detecta gen√©ricamente
]
# Aceptar cualquier tipo y validar manualmente
extracto_file = st.file_uploader("Subir Extracto Bancario (Excel)")  # Sin type=
if extracto_file:
    extension = extracto_file.name.split('.')[-1].lower()
    if extension not in ['xls', 'xlsx']:
        st.error(f"Formato no soportado para Extracto: {extension}. Usa .xls o .xlsx.")
        extracto_file = None

auxiliar_file = st.file_uploader("Subir Libro Auxiliar (Excel)")  # Sin type=
if auxiliar_file:
    extension = auxiliar_file.name.split('.')[-1].lower()
    if extension not in ['xls', 'xlsx']:
        st.error(f"Formato no soportado para Auxiliar: {extension}. Usa .xls o .xlsx.")
        auxiliar_file = None

# Inicializar estado de sesi√≥n
if 'invertir_signos' not in st.session_state:
    st.session_state.invertir_signos = False

def realizar_conciliacion(extracto_file, auxiliar_file, mes_conciliacion, invertir_signos, banco_seleccionado):
    # Definir columnas esperadas
    if banco_seleccionado == "Bancolombia":
        # Columnas espec√≠ficas para el extracto de Bancolombia (Coincidencia exacta: fecha, valor, descripci√≥n)
        # El campo 'numero_movimiento' se deja con una lista vac√≠a de variantes para que se genere vac√≠o/√∫nico.
        columnas_esperadas_extracto = {
            "fecha": ["fecha"],
            "monto": ["valor"],
            "concepto": ["descripci√≥n"],
            "numero_movimiento": [] # No se esperan variantes, por lo que quedar√° vac√≠o
        }
    else:
        # Columnas gen√©ricas para los dem√°s bancos (BTA, BBVA, Davivienda, etc.)
        # Estas son las columnas que ya ten√≠as definidas.
        columnas_esperadas_extracto = {
            "fecha": ["fecha de operaci√≥n", "fecha", "date", "fecha_operacion", "f. operaci√≥n", "fecha de sistema"],
            "monto": ["importe (cop)", "monto", "amount", "importe", "valor total"],
            "concepto": ["concepto", "descripci√≥n", "concepto banco", "descripcion", "transacci√≥n", "transaccion", "descripci√≥n motivo"],
            "numero_movimiento": ["n√∫mero de movimiento", "numero de movimiento", "movimiento", "no. movimiento", "num", "nro. documento", "documento"],
            "debitos": ["debitos", "d√©bitos", "debe", "cargo", "cargos", "valor d√©bito"],
            "creditos": ["creditos", "cr√©ditos", "haber", "abono", "abonos", "valor cr√©dito"]
        }
    columnas_esperadas_auxiliar = {
        "fecha": ["fecha", "date", "fecha de operaci√≥n", "fecha_operacion", "f. operaci√≥n"],
        "debitos": ["debitos", "d√©bitos", "debe", "cargo", "cargos", "valor d√©bito"],
        "creditos": ["creditos", "cr√©ditos", "haber", "abono", "abonos", "valor cr√©dito"],
        "nota": ["nota", "nota libro auxiliar", "descripci√≥n", "observaciones", "descripcion"],
        "numero_movimiento": ["doc num", "doc. num", "documento", "n√∫mero documento", "numero documento", "nro. documento"],
        "tercero": ["tercero", "Tercero", "proveedor"]
    }

    # Leer datos
    extracto_df = leer_datos_desde_encabezados(extracto_file, columnas_esperadas_extracto, "Extracto Bancario", banco_seleccionado=banco_seleccionado)
    auxiliar_df = leer_datos_desde_encabezados(auxiliar_file, columnas_esperadas_auxiliar, "Libro Auxiliar",banco_seleccionado="Generico")

    # Procesar montos
    auxiliar_df = procesar_montos(auxiliar_df, "Libro Auxiliar", es_extracto=False, banco_seleccionado="Generico")
    extracto_df = procesar_montos(
        extracto_df, "Extracto Bancario", es_extracto=True, invertir_signos=invertir_signos,
        banco_seleccionado=banco_seleccionado)

    # Estandarizar fechas
    auxiliar_df = estandarizar_fechas(auxiliar_df, "Libro Auxiliar", mes_conciliacion=None)
    extracto_df = estandarizar_fechas(extracto_df, "Extracto Bancario", mes_conciliacion=None, completar_anio=True, auxiliar_df=auxiliar_df)

    st.subheader("üïµÔ∏è An√°lisis de Datos Procesados del Extracto Bancario")
    st.info("Primeros 5 registros del Extracto Bancario despu√©s del procesamiento de encabezados, fechas y montos.")
    
    # Seleccionar las columnas clave y las originales de d√©bito/cr√©dito (si existen)
    columnas_clave = ['fecha', 'monto', 'concepto', 'numero_movimiento']
    columnas_opcionales = ['debitos', 'creditos']
    
    columnas_a_mostrar = [col for col in columnas_clave if col in extracto_df.columns]
    columnas_a_mostrar += [col for col in columnas_opcionales if col in extracto_df.columns and col not in columnas_a_mostrar]
    
    # Mostrar el DataFrame, incluyendo el tipo de datos (dtype)
    st.dataframe(
        extracto_df[columnas_a_mostrar].head(5),
        use_container_width=True
    )
    st.write(f"Tipos de datos (Dtypes) del Extracto Bancario: \n{extracto_df[columnas_a_mostrar].dtypes}")

    # Verificar si la columna 'monto' tiene valores diferentes de cero
    monto_cero = (extracto_df['monto'].abs() < 0.01).all() if 'monto' in extracto_df.columns else True
    
    if monto_cero:
        st.warning("‚ö†Ô∏è **Alerta:** La columna 'monto' parece ser cero o muy cercana a cero en todos los registros despu√©s de la conversi√≥n. Esto indica un posible problema con la interpretaci√≥n de las columnas de D√©bitos/Cr√©ditos o con la l√≥gica de signos.")

    # Filtrar por mes si se seleccion√≥
    if mes_conciliacion:
        extracto_df = estandarizar_fechas(extracto_df, "Extracto Bancario", mes_conciliacion=mes_conciliacion)
        auxiliar_df = estandarizar_fechas(auxiliar_df, "Libro Auxiliar", mes_conciliacion=mes_conciliacion)

    # Mostrar res√∫menes
    st.subheader("Resumen de datos cargados")
    st.write(f"Extracto bancario: {len(extracto_df)} movimientos")
    st.write(f"Libro auxiliar: {len(auxiliar_df)} movimientos")

    # Realizar conciliaci√≥n
    resultados_df = conciliar_banco_completo(extracto_df, auxiliar_df)
    
    return resultados_df, extracto_df, auxiliar_df

if extracto_file and auxiliar_file:
    try:
        # Realizar conciliaci√≥n inicial
        resultados_df, extracto_df, auxiliar_df = realizar_conciliacion(
            extracto_file, auxiliar_file, mes_conciliacion, st.session_state.invertir_signos,
            banco_seleccionado=banco_seleccionado
        )

        # Depurar resultados
        if resultados_df['fecha'].isna().any():
            st.write("Filas con NaT en 'fecha':")
            st.write(resultados_df[resultados_df['fecha'].isna()])

        # Mostrar resultados
        st.subheader("Resultados de la Conciliaci√≥n")
        conciliados = resultados_df[resultados_df['estado'] == 'Conciliado']
        no_conciliados = resultados_df[resultados_df['estado'] == 'No Conciliado']
        porcentaje_conciliados = len(conciliados) / len(resultados_df) * 100 if len(resultados_df) > 0 else 0
        
        st.write(f"Total de movimientos: {len(resultados_df)}")
        st.write(f"Movimientos conciliados: {len(conciliados)} ({porcentaje_conciliados:.1f}%)")
        st.write(f"Movimientos no conciliados: {len(no_conciliados)} ({len(no_conciliados)/len(resultados_df)*100:.1f}%)")

        # Distribuci√≥n por tipo de conciliaci√≥n
        st.write("Distribuci√≥n por tipo de conciliaci√≥n:")
        distribucion = resultados_df.groupby(['tipo_conciliacion', 'origen']).size().reset_index(name='subtotal')
        distribucion_pivot = distribucion.pivot_table(
            index='tipo_conciliacion', columns='origen', values='subtotal', fill_value=0
        ).reset_index()
        distribucion_pivot.columns = ['Tipo de Conciliaci√≥n', 'Extracto Bancario', 'Libro Auxiliar']
        distribucion_pivot['Cantidad Total'] = distribucion_pivot['Extracto Bancario'] + distribucion_pivot['Libro Auxiliar']
        distribucion_pivot = distribucion_pivot[['Tipo de Conciliaci√≥n', 'Extracto Bancario', 'Libro Auxiliar', 'Cantidad Total']]
        st.write(distribucion_pivot)

        st.write("Detalle de todos los movimientos:")
        st.write(resultados_df)

        # Generar Excel
        def generar_excel(resultados_df):
            output = BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                resultados_df.to_excel(writer, sheet_name="Resultados", index=False)
                aplicar_formato_excel(writer, resultados_df)
            output.seek(0)
            return output

        excel_data = generar_excel(resultados_df)
        st.download_button(
            label="Descargar Resultados en Excel",
            data=excel_data,
            file_name="resultados_conciliacion.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        # Mostrar bot√≥n si el porcentaje de conciliados es menor al 20%
        if porcentaje_conciliados < 20:
            st.warning("El porcentaje de movimientos conciliados es bajo. ¬øLos signos de d√©bitos/cr√©ditos est√°n invertidos en el extracto?")
            if st.button("Invertir valores d√©bitos y cr√©ditos en Extracto Bancario"):
                st.session_state.invertir_signos = not st.session_state.invertir_signos
                st.rerun()  # Forzar reejecuci√≥n de la app

    except Exception as e:
        st.error(f"Error al procesar los archivos: {e}")
        st.exception(e)
else:
    st.info("Por favor, sube ambos archivos para comenzar la conciliaci√≥n.")
